# Database

Let's create a simple Markdown database, associated with each file.

With base-64-encoded directory names, or to not exceed allowed name length: rather create directories reflecting some time order, and have id's, like the following, and inside there is sourcehttp.md to make http client find it instantly. Where we use Flask, is the Client: it's just overly mapped to Spider's client database, where the Spider also sees the two Git instances, which must be hinted in standard way at root page. The Spider must be able to confirm the same version of the server, or update database where there is tree of original versions and Git brances, clones and updates, or where they are merged together there are two chapters with "continue" or "expand the slice of list", with some preview where Garbage Collector removes the 3-4 times repetitions intelligently.

Each AI or Logic Machine or User with Wiki can update their Flask Database; they can reflect internally (root folder always has address: "/") or externally the whole directory or folder tree:
- Directory tree is what is inside both Gits
- Folder tree is what is in Flask output
- Before committing to Flask, which is kind of second-main for special purpose, we update the cache and hash files and run setup.py or configuration.py if exists, where any clone might not have it, for it does not have any preparation; we also run databasereset.py, which removes all intermediate database files and recreates them based on real data - which is in Markdown Database. Then, when it's committed to Flask, others can continue doing their commits (otherwise they can also use intermediate branch, where we could allow more non-functional code examples and drafts to work collectively, and subforks which can sometimes update their database from upstream, then when most items are solved commit some summary items there: for example, a commit for a month should not exceed 2 open items on average, measured on some gaussian curve).
- AI, Logic Machine or User would not run inside, but keep their webpage like database of code, markdown text and links to free and commercial resources.

In later time:
- We create git branches for normal editing
- Before committing to flask
  - We do not accept any other commits in this period
  - We update all the

Markdown Database:
- Entering an item to Markdown database would use "Markdown" directory with folders with names of files and folders, extensions ".fl" and ".fd" and ".dr" mapping to file, folder and directory, where folder is part of output and directory contains the cache, database, intermediate files.
- Each file would contain:
  - Markdown
  - Special ending with paragraph mark followed by: EOF
    - Folder (extension removed, it would back-convert the result into file and folder format, where _"list"_ gives garbage-collected selection, and each possible static or dynamic file can still be requested), DHTML (default, .html), HTML (.htm), Json (.json.htm, Download: .json), Markdown, [Py (.py: Download, .py.html: View), Anki (download and view), Jsonl (download and view)]; each file has a visible folder with extension removed, several files share the folder. This folder attachment can be left end of file of Markdown database item file, containing one recording.
      - Dynamic files would contain Codes: before last filename, there is the code in letters I, O, A, E, where index is encoded by bits: I=00, O=01, A=10 and E=11; U=0 and V=1. Sometimes, another interpretation of Laegna letters and digits, of the same length, but only case-sensitive alphanumeric, would be used. Code helps to restore the same version.
      - Version and Id is used: user can, in some commits, manually change the version; for Flask build, each Version is separated by Id from other commits with same version.
      - Use links for images and media, which download the file, and mark them as inner: downloaded html file could have structural format with this, especially the Json which marks the link for Spider: one can add Markdown content to the block, and Json will return the blocks: this is the actual reason why we cannot convert back to Markdown, we don't have bebug file.
    - Python scripts continue for user after EOF and they can add new chapters to the end, for a while, until timeoff is reached; both sides can register this conversation to a web page. Notice you can surf inside the public database, you just follow the "Markdown" link. Notice the item is dynamic in the user view, and can generate it's own content, which needs to replace the default content: plain markdown with attachments and views.
    - Spider could hang around purely based on Markdown or Json content; preferrably also with anki and jsonl content (used for AI training, anki also for user lessons for quality collections of tasks suitable for humans: preferred format might change): the output, based.
    - Somewhere, law paragraph mark (ยง) would be used in command "ยง Database Upload Sucess".
    - The same database entry session would continue to extend the file, and use "ยง Commit." where the new content should appear. Let's hope "append" methods are safe. The client will get dynamic content, based on whether they run the scripts in their home computer or server, or whether a server would run them, or whether they use the cached pages.
    - Cached pages can contain dynamic content: They create Markdown database items, which are able to contain, wich "# ยง " comment in Python at the first lines of a script, where you can exclude this option by adding an empty line at beginning of script, or sending it to your own interpreter, where you have python templates: each template would pattern match whether it's specific type of script, for example it has to find, in certain order, how for "elementary math" basic math operations are used, and with readable (correct) variable names and enough characters of comments at specified place, the Q & A trainer is called with specified parameters and the card is added to card collection; with backlinking the pages would recursively load, and where they have execution rights, they would immediately run some triggers, and later some: or, at the script text, they could check the status at each run, following certain condition where the server could confirm that they refer to this status variable and finish the block with proper command.

    __Template__:
    - Template exists for database items, where it could for example contain chapter tree list, with remarks that there are no chapters in between, or that this is the original, selected ordering of chapters, or that there will be a number of intermediate chapters, subdocument or nested document or even a book (another tree will be created, and this will behave like a root node, also contained in it's chapter lists of books, rather garbage-collected so that the preferred books would initially appear, until you click "continue ->", it's "continue ->" and it's "continue ->", each time getting a larger list ..well this for heavy users).

    We create such maps ("Controllers" of an execution):
    - Create controller for each "import" clause, reflecting how it could be used by an user and using libraries for reflections.
    - Use empty "for()" and "if()" cycles, in Python "for:" and "if:" and "elif:".
      - Inside, the templates would be ordered for function calls, where we also see whether certain thing is necessary.
      - It would create ability to parse the code and say, whether "if" and "for" conditions can be resolved that they are called in specified order.
      - It has syntax highlighter mode, where block structure might be inconsistent, but the meaning is generally known.
    - Outside, there will be also the templates:
      - What methods the user needs to run; what variables to use, which operations and where, for example constructing numbers based on math formula and adding them into a String.
      - User will get a manual, which does not expect knowing Python: it will be, rather, a standardized semantics for creating templates and cards for such math.
      - Later, we would follow variable streams: input and output. It could be structured based on which line depends on which line; and cached based on which part can be restored later.
    
    Python scripts in parts of database will require this.

    To add something to database:
    - Create md file at random position.
    - Mark some chapter a "database item", where it could use it's name as key.
    - Generated pages can be "database items", where the Laegna number (code of IOAE, perhaps UV letters is created for each generator; gen=1, 2, 3, etc. and 0 for special purpose like "gen03" where zeroes reflect the size of collection, how many digits it takes to write smallest and largest index numbers, where generator can also be multidimensional: numbered like "1 1 2" it takes selections 1, 1 and 2, where user creates python class for decoding generator names; it contains a list of random generator seed numbers, like perhaps 10 items from indexes 0 to 9; the databases at these indexes will be cached and served to user, while they must include their new generators or generations into new reflections of random seeds into small indexes).
    - For example, form submit can also add a chapter, to the current file, where the database item would be contained: then, in actuality, it already creates a database draft, because the added chapter would be separate item in directory tree, and marked position in file "with @ target syntax" would create a target point where they appear; things appended on filesystem level would be processed before the templates are ran.

    What we do later:
    - Before committing to Flask git, perhaps using one intermediate git to not distract others in committing, we would run the database update script, which collects the database from random items around; it also creates caches for database items in other servers, which have "@@ "-backlinked some "@"-backlink targets, and run the code locally, but then also generate new paragraph marks to run some of the code later, for example removing backslash (\\) before some paragraph marks, where the content has triggered something.

Each database item creates a Prolog implementation of it's containment: We use Prolog to process queries, which are given in interface, or it's dynamic.

The Static Prolog:
- Interface for Prolog API contains the implementation, where Prolog queries are associated with List, Dictionary, Object, Class, etc. structures; this could be prolog processor code block with paragraph mark. Here, prolog will get a class, which for example has: given the filesystem node address including named chapter position or target position for links, where one might write their own content, especially if they receive public position (positive) feedback. Each of such target objects is an object or identifier value in Prolog.
- Directly, they can execute Prolog code, it would be nice if the code is preprocessed and any internet object is submitted where link is used instead of a variable of the same type (for example, html instance with it's source attribute set to the link).
- Users will make sure that by Prolog databases, their things are associated properly. Notice that rebuilder is using the current Git: the Flask filesystem will not change dramatically, if it now downloads from it's own git, the new server into new folder, and creates subfolders to old servers, which have new versions, creating a branch tree of subfolders. Those items are visible as objects in database prolog.
- For database item, it's template, md file or it's named chapter etc., we generate Prolog headings: it's a static content that this object exists, one you can copy to Prolog.
- While we check the compability of Prolog: we have natural language queries converted to Prolog, but this conversion and original query is used creatively by others, given that it's _Only The Logical Syntax_ of given objects: we use logic in everyday life, and basically Prolog can be used: A) as a Language or B) as a notation of Logic - where you are allowed to use it in both meanings, and you use "optimized-for: prolog-version", "optimized-for: version-of-your-logic-processor", where you might see the same "true" and "false" notions from your own perspective, for example how these values, of their actual object, affect you in reality and how you would refer to these logical constructs, rather than interpreting them mechanically like a program.

Kind of Theorem: each logic processing machine, also contains a standard usable as encoding of logic, which can be used similarly to statement like "A => B", which can rather follow our own logic than be executable in any given machine; for example you use Prolog's :- in the same way, where it does implication, or you use random part of list literal to even break the syntax: statistical syntax error should automatically recover this to AI and user modes and turn off any automated execution; for example, each time import fails, user removes the first import statement, later first n statements, and it becomes more true that if something here is machine-executable, it probably means something else. If statements are ran in row, with some downtimes and syntax errors by some users with these tags and hashes, it's bad.

For scripts personally generated for users, "home/usernameorlinkshortcut/...", where "..." is a local link; their Spider can log in and download this: for their unsafe code, they run it locally where the paragraph marks are disabled and need special registering for our server. The user pages could upload it to their Flask client, or to the Server, which simply creates the folder tree.

There exists hashmap file, let's call it .hm.md: In main chapter, there is in single paragraph the hash of main chapter or the root folder of this subsystem, and the hashes of specific files and chapters or link targets follow; separate main headers generate hashes for other servers, and git version is also logged, where files have also their own indexes: the versions are not applied if they have not been changed, redirecting it back. Sections, based on Git, can be watched for versions, and backlinks for referrers.

Backlinks, before commit to Flask:
- Their databases will be downloaded
- The resulting script also autodownloads updates, which means you don't commit to read this; anyway, the files are not so static and referrable, under your version control.
- Also, more sources can appear in Server, Flask and Spider: all systems are dynamic, but they have this static source, which reflects them.
- Self-reflection: the Flask commit builder could also run intermediate page, let the information compile there - using rather the Server than the Client -, and more files would appear in "gen" folder, where the generated additions appear: in the Client page, anyway, unlike the programmer a Client does not care, which part is generated: the gen part of link does not appear and the gen<x> with x being random seed page number, would mean another thing.

We keep the flow of our application

Flask distribution:
- Also contains a hash map, where each chapter and other part of content is indexed before the server upload.

## Timing

The processes are ran:
- Inside each preparation, where the content is prebuilt from Git repository to it's own, and the new version is finally committed back to original Git, perhaps one could ignore the generated database or autoscript would always also update a version, which is free of such content: it would take care, what is the condition each update should leave the other database into; different Flask pages might also have different AI support. Pages, which have not been committed, could not run their scripts in this phase: anything what happens here, adds items to databases and indexes or hashmaps, creates objects as result of calculations, and is optimized like on stage -1: for program, this takes a moment to load, which was a calculation. Precalculated things are very fast to load.
- Dynamic pages, rather, win from their being dynamic: that we can add things at runtime, where the Flask page would rather watch the last version files than it's own version, and so you can add numbers to old versions now: creating a branch to continue older development or to reverse it back to it's original state, for example now emulators run this version of Python directly without a flaw (but perhaps later they want to run the later version, which contained some comfort updates, you don't know what is the last update: to contain your original code in interpretative-mode, for example, where an AI would analyze the original intent of this specific commit).

## MDDB Logic

Markdown Database Logic:
- You use targets to append your database inputs.
- You make sure that you can permanently store some of your generated stuff, where Markdown is stored to Md, Json to Js, and the HTML and DHTML can be generated from Js blocks, dynamically, where they should have attributes to refer back to line, character, byte and utf-8 position in file including the line feeds and EOF's (put the file into initializer, of the class reflecting it, but what follows our "EOF" is first some set of updates, where another "EOF" would extend the first one after updates and commits; finally there is some dynamic flow and when serving, it would extend by paragraph-mark-scripts, adding to the end - or to parsed document, for example replacing or updating it).

## Conclusion

The site is quite dynamic,

but we are still having kind of copy-and-paste logic, where the AI could simply explain in which file they did put the form, and what they did.

## Directory.md

Let's have a Directory.md file for each Directory: Jinja2 template can be executed around it, in which case it will display each page of this directory as soon as it goes to Markdown, but before the Markdown is passed to higher-level parsers. This basically, can refer to directory chapters and files in Markdown, processing that they will be ordered as in this file, also "# *" would mark the rest of directories, or perhaps mentioning ones between two mentioned chapters.

Open for's and if's should be added to this Markdown: they could read some cycles.

It could be closed that in this modification, the directory or folder will not contain additional projected content.

An user, to process the form into database:
- Create the form in HTML editor
- Create an initial template, where Jinja2 template would use it to create Markdown page.
- You can add a backlink to your target at Form page to contain the result here, with heavy Garbage Collection (or mapping) of the backlink or the chapter, only the titles would appear.
- Jinja template
  - It would contain some content
  - Then, it would contain "EOF" symbol: a paragraph mark followed by remark that this is successful entry, not a broken or half file, which should be processed by recovery modes.

## Prolog

The cards need to be connected with Prolog, where basically anything in file could register some logical objects for it, either to real Prolog you can use to have DB interface, where it points to objects your code can load and run, and creates connections between them.

Prolog followers should be able to be created by Jinja2:
- Enter a Prolog Query
- In Jinja2, the result would allow to generate for's and if's.
- This could affect Markdown, Python code etc.
  - This could affect HTML, where the HTML results are also structured and go through additional HTML templates, parsers, syntax highlighters etc.

We consider Prolog rather a complete language, and here our implementation is very small, but Prolog, for example, could be then used to connect a database item in distant server with your corrections to it. This might be your personal database of reflection, in which case we should allow the property "weak" for backlinks: for example, your AI trained at specific field, needs to know the additions in this field to common data; for example, an engineer would add 3d-renderings of pieces for your wood products or additional example code for your applications, reflecting back, but not mentioned by you; this could be their own science and whole scientists, so this adaption of your would be learnt by their own AI, when learning yours: it would add hidden pages to targets.

Whoever is forward-linking to your page, including it in theirs, can freely use your targets: they can add content, which does not come from your friend list, to their reflection.

## AI

AI would be able to follow the Text, Code and Prolog, and for example each of them gets many examples about how to translate it into Q&A card, or Q&A&D (when context is added, it's my own acronym for Question-Answer-Documentation, where I did not see another one; another one, perhaps later I adapt).

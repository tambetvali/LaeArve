# Jan

Minimalistic chat implementation, which works well with small models - less attention is compensated that it does not aim to read docs or understand much context.

This could be your waitress: when all the models are busy, it can still answer fast even when resources are in use, from the overleft: given you have 0.5B and 1.0B models.
# üÉè Our Bots

We define capable bot as such:
- A bot, which is capable to work with Laegna combinations in equal quality with this proposed bot, even if it's general-intelligence standard bot not specifically aware of Laegna, would be considered either our or third party, free from other properties, _implementation_ in the most direct interface usage of such class definition; that bot would be a _third-party implementation of our standard_ not in causal, but in future and application or purpose-oriented way, much as how an oracle would prevision. You could get particularly good future estimations from AI in some particular fields or periods, and rather better if you do estimable (I tried to translate e-stimulus to e-stimation) work in rather quality criteria. So what is defined here, is _Laegna Assembler Bot_, who needs to learn the decimal capabilities for indexing of Laegna numbers in decimal computer.

What follows? We try to hack python or other language to express Laegna numbers. Thus we decode each x, y combination of the real-imaginary axe or frequency and it's z position of a real number axe; we call everything, which follows this criteria in digit space, and "even" number; which is unlike "odd": what is in non-repetitive cycles or scales, we need to _optimize_, while some others we can _project locally_, by local optimum machine which scans constants in space-stateless localized manner, optimizing performance and scope. When we color Laegna Numbers, the shape must make sense: they are Fourier diagrams for multidimensional numbers.

We prove that for plain number, it exists in an abstract space and we don't need to know more than decimals. It's an absolute cubic, even if only the next layer does it in curved space: this one, to it's degree of knowledge, is a _transcender_ bot, which is first trained on decimal system, and then retrained to extended decimal system with training mixed to decimal system training. We mix training, because the operations appear rather metaphysically: if they are repeated in calculation scope, either _reasons_ or _mistakes_ might appear, for your work.

So:

789
456
123
  0

Five and Zero are constants: what is overleft, removing last value, is unknown of the two.

With one value, it's a positive five, which determines the behavior with deccelerating positions: it always means one. For example, 65 A's in minus one octave, basis for complex number space diagonally, where the number digit does not accelerate in deccelerated space and in higher space, we would compare it going backwards already (it depends on your constants): 65 A's is then just 65, and it's simple to achieve: from 4 index and power positions, two indexes O and A, sub left and sub right, form - and +: number O or A themselves, on these positions, would empower themselves, whereas E on both position would accelerate the current position, doubling the dimension so backframing an infinity, which is value of Y given that the number space is equal: doing balanced operations with two distinct number systems, with statistical precision.

## Laegnamos the denary system
__We now _Latimos_ it, but I did put it to opposite, and denary against decimal: to Z'ify the goals we are set.

Digits:

Notice: "[" and "]" are specifiers of number pieces. This calculator cares about the numbers in every set, and does not leave space for higher-level compilers, which have more to do with syntax than number digits and simple operations: so here, if we need to specify a digit part, we use "[" and "]", and also tu specify the sub-digit attention.

Letters have two forms: capital and not. We want this dimension, but the font does not accept small-caps numerics; so "%" sign before a number digit would show _minimal_ version of it, where we don't care what it means in programming languages or even more advanced calculators of the same math.

Before a number, comes the tricolor:
- It's a set of signs to form a number of the space where it's attached.

This bot will never learn:
- Actual relations to Laegna number systems
- It's implications

Instead it learns perfect generation of cards of it's class:
- It can give answers to tasks in Laegna system.
- It can generate tasks in Laegna system.

This Book will be the basis of implementation of Laegna Number System: we reach Python Native Support by hacking it's ranges.

We write Laegna preliminary, decimal-system-based implementation in such way:

13:12:7

Where the number is 13, in space range between 12 and 7 backwards (R is rather minus, but the _position_ fluently flows _further_ in this).

This first layer of cards will be much more intelligent, _in Laegna sense of the word!_ It would be intelligent in basis of Laegna - and moreover, able to generalize it somehow in other terms, which would make it not to _generalize_ into Laegna, but into a philosophical speculation: for example, either decimal, or Laegna system.

Based on this generalization, which directly implements the basic properties, we accumulate from decimal-based understanding to Laegna; where for centuries coming, each historic work was not aware of Laegna: you still might start from some binary basis, to form combinations of 2*2, and wait before it's exponential counterpart: where this would become imponentially in regards to infinity-relation, quite fast in the calculation process before infinity becomes annoying.

We also implement Complex Decimal System:

9
8 7 6
5 4 3
2 1 0

9 and 4 are now opponentially having the space-centered application, where 9, no matter what the number, is in first position.

Then we have decimal system of two frequencies:

9
8 7 6
5 4 3
2 1 0

9 8 7
6 5 4
3 2 1
    0

Where we see the symmetries:
 0
4 5
 9

This diamond is the Golden Angle, where energy is passing perfectly the _Crown_ and the _Root_, in __Buddhist sense__. Rather like Taoists, we use two frequencies, and they meet in the center. Within this boundary of decimal system, we have done it this way.

The Diamond Space: we see 8 directions around the centers and the poles, which we want to linearize, but with dimensional particle containing at least some, a minimal amount of information.

The next resolution down is such, which does not keep the number position - this is done rather by letters going _up_, because we cannot compare them from head dynamically.

9
 4 3
  5
 1 2
 4 3
  5
 1 2
    0

This dimension has no specific information-clarity for separating frequential areas, where we map square positions and not number values: the last and first digits are not mappable to other version.

This way, we describe a _finite number_: this 0 or 9 is the digit length, which needs the next frequential explanation, one digit spread to next frequency; it behaves like 4-based laegna impl., that in it's wider space it has first accent only by 1 digit; E and I also do it only by 1 digit: in Laegna Numbers, this is _half_, an important constant, but in decimal: a little, random number floating around. On the other side, you have lost one digit in the _middle_, if you project from upper to lower.

This maps property our Laegna squares would need:
- __What is__ Linear _Laegna Number_.
- __Has__ Exponential _Decimal Counterpart_.

This, because: we wanted to linearize exponentiality in Decimal Systems. So we create one with this trait in perfect implementation: coming very fast. Real lower octave is speeding down fast, but this one is rather slow and does so without any particular purpose: this is the next unit, not yet completely space-bound, which shows curves where we map lines. It assumes such _projection_ and by changing it's parameters, we can fit otherwise neutral Laena numbers to expolinear conversation, where linear and exponential scales can be mapped. Complex numbers might be needed to raise the complexity of this space: complexity is information density to express a smooth set of it's piece of curvature, containing qualities and quantities and being assumed intelligently, creatively and openly to varying cultures.

Sublinear scope, such as base 4 and base 2, linear downwards, also base 1 which is also square of itself, care about their linear multiplicator rather than subspace: where R and T are equal, we reach perfect calculations in analyzing data densities.

More to find: in code, soon to become (because docs are for introduction in Books part, where we really need specialized Chapters for number types: an AI really learns from the code - consider, it's a simple and learning-degree code, as it takes simple basis).
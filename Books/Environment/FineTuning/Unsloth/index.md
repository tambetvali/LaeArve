# Unsloth


## AI

Yes, there are open alternatives to Torchtune that you can use without waiting for gated access. Here are a couple of options:

__Unsloth__:
- __Unsloth__ is designed for efficient fine-tuning, especially on limited GPU resources. It supports open models like LLaMA 2 and Mistral and is optimized for speed and memory usage.
- This is a great choice if you're working with smaller or older GPUs.
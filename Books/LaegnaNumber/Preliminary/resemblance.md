# Decimal-resemblance

__Background__:

An AI and the user has much data about the decimal background.

_Hypothesis_, __Conjectured__ (__which means__: in effect):

Existing AI is aqcuintainted with Dechexaplha DHA counting system:

__DHA__: we introduce this name for our Latin-Laegna number script.

Resemblance:
- AI has studied 0-9 in this order, which it can compare.
- AI has studied A-E as first digit positions after 9, studying hex.
- Those well-known distributions are kept sorted by our implementation.
- Using 1-4 for corners in different ways is not uncommon, as well as 1-2 for opposition or 1 for just having something.
- Alphabet and ordering things based on alphabet is a common strategy.

By having numbers within this light, AI can: study the correspondences with existing mathematics and it's theorem.

Problem to be solved: patterns of AI often contain literal values and tokens, and their necessary correlations, where related tokens might have encoding, where digit-wise operation does not necessarily generalize. Having, for example, coded 1-8 into A, B, C, D etc. is common example in letter games, children simple crypto, examples of using different digits. Nodes can be indexed in this order, dictionaries can use these letters just as titles for chapters and sections, and otherwere _something is done with this order_, for example dictionary first-two-letter-pairs are somewhere ordered and numbered, having clear correlation to just counting the possibilities as if this was a number system; actually an estimate of _division_ of members in this range by a volatile constant or statistical approximation.

Optimizer:
- In addition to rounded and generalized values, the exact values are perfect reflections of the metaphysical position, rather than mathematical average.
- Feeding several categories randomly at the same process, where the categories themselves are far from having definite order, then allows _operations_ between them, as the information is kind of spread between them; the exact original position is a very good classificator, where leaving some to the past means that the dispositions do not interact so well.

Our AI Rule
-----------

We should organize the AI student in the following way:

We got:
- Model
- The randomized training material
  - It allows to choose related topic
  - It allows to regenerate the lesson cards
    over and over, and if it's able, does
    mathematical approximation.
- Mathematical approximation: if known type of
  code with randomization is in AI set of code
  and it's output, for example where the code
  is asked to be "answered" with it's output:
- The statistics of each conversation.
- The historic part

Our model will be able:
- Analyze the Issue tracking
  - It has access to GitHub of our documents
    and related tasks.
  - It has access to every project management
    system: the Issues of GitHub.
  - It can analyze many Version Control and Issue Tracking webpages, including Laegna Math Website.

__Let's Branch the Model__:

New model is trained based on half of the Laegna issues, for example cycles, which affected only certain branch: it's not bad if some information is missing and some is leaking, given it's a normal noise factor.

The model issue-tracks, historically, the whole thing having Context Model Access to previous code of each cycle, but not the new code; the previous docs with issues, but not the new docs. This happens within separate books, with separate users.

Having the validation set is loss of information: we run this several times with different sets of training and validation; we do passes, where we slowly generalize out the validations, leaving only the training set. Failure data is collected later to _gradient tensor models_, which emulate gradient tensors: they collect the gradients of final lessons, where we need to collect public chats, especially in regards to Development of Laegna. Let's assume this branch model will feed the main model with cards it can create intelligently based on Laegna input of it's specific topics: for example, before answering a Laegna-related "unanswered question" or implementing a feature, we submit the feature plan with the problem description, initial ideas for architecture etc.

This blind test, when successful - it creates models, which are now used to generate cards for the next subsequent model. 

This is to establish the Laegna innovative
conception of the Number Systems:
- We will keep this encoding in Laegna, and
  subsequently we call this "Standard Encoding", vs. Laegna Encoding, which then becomes a subcase. The Standard Encoding is allowed to have two roots: either it's defined on Laegna, or on Latin system, which means we provide circular reference later:
  
  _TODREAM_: In regards to later Laegna, we need to do this purely in Laegna implementation, which is already implemented on this Latin class. This is interesting question, how to remap the variables: new functions need to sync along with initial implementation, where it adds accessors to dimensions and new dimensions, and probably it needs to collect it's own dimension data from history, so better there is not much history when this class starts. This, because we need exercises in base system to make Laegna an ideal self-referencial framework of definitions and we need to push each kind of self-referenciality. Currently, it's an optimization far too big to dream of it. _Notice:_ todream, in beginning of this paragraph, is defined with italic, not bold; this means that it's _using_ this term as we need many such blocks and they don't share _identity_, which we would mark bold in such case.


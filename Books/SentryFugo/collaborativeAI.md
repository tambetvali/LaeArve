# Collaborative AI

Intelligence need 1: Embeddings and Fine-tunings.

We have several needs for our webpage:
- To create embeddings: embeddings for documents and their parts should be created; there are many models, which can embed, and they have different power and different intelligence levels. Power users, for example, could generate embeddings with powerful machines, then simplify them to level of our bot.
  - We need embeddings to our static pages, which could also fetched if those are used as Documentation.
  - We need embeddings to our dynamic pages, for example a model, which would learn our GET variables into an embedding space of more generic model to do embeddings; the target AI would see dynamic content as context.
- To learn the content (to fine-tune): fine-tuned models, which are fine-tuned on our page, will have more "intuitive" (dointuitive) understanding of our content; it would be able to discuss our content and to understand the model for Laegna embeddings.
  - We need fine-tuners to study the static pages, or the cards, which are generated for them.
  - We need fine-tuners to study the dynamically generated content, running the dynamic generator and fine-tuning for this.

The collaborative AI would:
- We don't have the disk space for all of this, but for example we might be registered in service for such collaboration, which would register each collaborator and create on-line list, with public and password-protected lists of models and embeddings for us.
- It would track history: where other users continue to fine-tune with different materials, it would be able to understand the dependency tree and integrate the past sources so that while fine-tuning on new data, the AI would also get some percentage of flow of past data or repetition of past static data. We want the original variables to interact in the new context and the bot would, by my intuition, definitely learn better if the variables remain interacting.

Given a number of fine-tuned models, an integrator could learn questions and answers from each: this is normal that an AI is generating training materials for another AI.

## Intelligent Variance of Cards

Intelligence Need 2: Variance and entropy.

We also need intelligent modificators:
- When I create a generator for math lessons for an AI, it needs the following:
  - More templates: for example, it might generate tasks like Q:"1+1", A:"2". Template would be able to turn it into: Q:"Ann gave Jason one egg, while Jason already had one egg. How many Eggs does Jason Have?", A:"Jason, given he had only that one egg, now has two eggs for cooking this evening." Each math pattern should accept templates for actual, more creative cards.
  - An AI model is welcome to be trained to recognize certain formats of questions and turn them into creative cards. For example, this AI might not know numbers in particular - it might only recognize that "1" and "2" are numbers, and the operation of addition; it's training would simply be to copy the numbers into tasks, which it can make intelligently - for example replacing eggs with apples, apples with oranges.
    - This is a generic question: given that this Q&A pair is true, then which Q&A pairs would be true by implication? For example, if Jason got two eggs if one egg was added to his one egg, it might be tautological that if Jason had one apple, adding one apple would give two apples - the target system would not know math, but such combinatorics.

My idea: AI models in different roles could take our data further step-by-step, and come back with innovative solutions of research where we have less variance and less creativity.

Result:
- In distributive network, the user who created additional cards would create link target for our dynamic generator of cards, for example adding it's type to index; there could be also integrators, which get the cards from many users and integrate them into single list.
- Once we accept the link target, or for example link targets not considered spam by system, where we collect them (we can allow several systems to receive and verify pings for this, and aggregate the results), we have _linked_ them even if we don't have this direct link; our system would add this to prioritizer of our page: our users, now, are free to utilize these cards.

## Manual Cards

Given the task for autogenerator, an user would read the task of autogenerator:
- For example, the task is to utilize 4 basic math operations with numbers, generate the Calculator-format math expression and it's calculator-format result.
  - Calculators would learn this directly, so we need the original format to be available. We can create a shortcut for calculator page, which inherits the generator _at this stage of generation_ and does not touch added cards.
  - Users can create pages, which link back to our calculator "@@ [Basic Math Ops](http://oursystem.ai/books/basicmath/basicops)" - two @'s create a link target in our format.
    - The link target: it would recommend our page to add those cards as part of this section; this could be card list of the generator.
    - Our system would be free to include these cards, and we can create trust lists of users and communities.

Manualization: given we write a good manual, user could add those cards to their space / spaces, and link back to us to confirm those are our cards.